# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17JcI8xc2o-UeKrxGKnFAqcURHn4lW90t
"""

nov_data=spark.read.format("csv").option("header","true").load(r"raw_data/2019-Nov.csv")          

clean_nov=nov_data.na.drop("any")

clean_nov.printSchema()

from pyspark.sql import SparkSession

from pyspark.sql.functions import split

from pyspark.sql.functions import date_format

new_data=clean_nov.withColumn('category', split(('category_code'), '\\.').getItem(0)).withColumn('sub_catogery', split(('category_code'), '\\.').getItem(1))

b=new_data.withColumn('date', split(('event_time'), ' ').getItem(0)).withColumn('time', split(('event_time'), ' ').getItem(1))

d=b.withColumn("day",  date_format('date', 'E').alias('dow_string'))

d.createOrReplaceTempView("nov_data")

Customer_count=spark.sql("select count(user_id) p_customer from nov_data where event_type='purchase' group by user_id having count(user_id)>1")

Customer_count.write.format("orc").saveAsTable("Customer_count_Purchase")

purch=spark.sql("select count(event_type) event_type_p,sum(price) total,date from nov_data where event_type='purchase' group by date")

view=spark.sql("select count(event_type) event_type_v,date from nov_data where event_type='view' group by date")

cart=spark.sql("select count(event_type) event_type_c,date from nov_data where event_type='cart' group by date")

join=spark.sql("select a.event_type_p,a.total, a.date, b.event_type_v,c.event_type_c from (select count(event_type) event_type_p,sum(price) total,date from nov_data where event_type='purchase' group by date) as a,(select count(event_type) event_type_v,date from nov_data where event_type='view' group by date) as b,(select count(event_type) event_type_c,date from nov_data where event_type='cart' group by date) as c where a.date=b.date and b.date=c.date")

join.write.format("orc").saveAsTable("p_v_c_date")

purch1=spark.sql("select count(event_type) event_type_p,sum(price) total,day from nov_data where event_type='purchase' group by day")

view2=spark.sql("select count(event_type) event_type_v,day from nov_data where event_type='view' group by day")

cart2=spark.sql("select count(event_type) event_type_c,day from nov_data where event_type='cart' group by day")

join2=spark.sql("select a.event_type_p,a.total, a.day, b.event_type_v,c.event_type_c from (select count(event_type) event_type_p,sum(price) total,day from nov_data where event_type='purchase' group by day) as a,(select count(event_type) event_type_v,day from nov_data where event_type='view' group by day) as b,(select count(event_type) event_type_c,day from nov_data where event_type='cart' group by day) as c where a.day=b.day and b.day=c.day")

join2.write.format("orc").saveAsTable("p_v_c_day")

cat_c=spark.sql("select count(event_type) event_type_c,sum(price) total,category from nov_data where event_type='cart' group by category")

cat_v=spark.sql("select count(event_type) event_type_v,category from nov_data where event_type='view' group by category")

cat_p=spark.sql("select count(event_type) event_type_p,category from nov_data where event_type='purchase' group by category")

join3=spark.sql("select a.event_type_c,a.total, a.category, b.event_type_v,c.event_type_p from (select count(event_type) event_type_c,sum(price) total,category from nov_data where event_type='cart' group by category) as a,(select count(event_type) event_type_v,category from nov_data where event_type='view' group by category) as b,(select count(event_type) event_type_p,category from nov_data where event_type='purchase' group by category) as c where a.category=b.category and b.category=c.category")

join3.write.format("orc").saveAsTable("p_v_c_category")